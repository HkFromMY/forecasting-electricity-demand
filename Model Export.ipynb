{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timesteps from 1h to 24h \n",
    "df = pd.read_csv(\"cleaned_data\\\\24timestep1h.csv\", parse_dates=['tstp'])\n",
    "df = df.drop(['date'], axis=1) # date column when joined with the holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
    "\n",
    "def create_fourier(date_index):\n",
    "    fourier = CalendarFourier(\n",
    "        freq='D',\n",
    "        order=1\n",
    "    )\n",
    "    dp = DeterministicProcess(\n",
    "        index=date_index,\n",
    "        constant=True,\n",
    "        order=1,\n",
    "        seasonal=True,\n",
    "        additional_terms=[fourier],\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usrer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Usrer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# label encoding\n",
    "precip_encoder = OneHotEncoder(sparse_output=False)\n",
    "holiday_encoder = OneHotEncoder(sparse_output=False)\n",
    "summary_encoder = OneHotEncoder(sparse_output=False)\n",
    "household_encoder = LabelEncoder()\n",
    "stdor_encoder = OneHotEncoder(sparse_output=False)\n",
    "acorn_encoder = LabelEncoder()\n",
    "\n",
    "precip_labels = precip_encoder.fit_transform(df[['precipType']])\n",
    "holiday_labels = holiday_encoder.fit_transform(df[['Type']])\n",
    "summary_labels = summary_encoder.fit_transform(df[['summary']])\n",
    "household_labels = household_encoder.fit_transform(df[['LCLid']])\n",
    "stdor_labels = stdor_encoder.fit_transform(df[['stdorToU']])\n",
    "acorn_labels = acorn_encoder.fit_transform(df[['Acorn']])\n",
    "\n",
    "precip_labels = pd.DataFrame(precip_labels, columns=precip_encoder.get_feature_names_out()).astype('int8')\n",
    "holiday_labels = pd.DataFrame(holiday_labels, columns=holiday_encoder.get_feature_names_out()).astype('int8')\n",
    "summary_labels = pd.DataFrame(summary_labels, columns=summary_encoder.get_feature_names_out()).astype('int8')\n",
    "household_labels = pd.DataFrame(household_labels, columns=['household_label']).astype('int8')\n",
    "stdor_labels = pd.DataFrame(stdor_labels, columns=stdor_encoder.get_feature_names_out()).astype('int8')\n",
    "acorn_labels = pd.DataFrame(acorn_labels, columns=['acorn_label']).astype('int8')\n",
    "\n",
    "encoded_df = pd.concat([df, precip_labels, holiday_labels, summary_labels, household_labels, stdor_labels, acorn_labels], axis=1)\n",
    "encoded_df = encoded_df.drop(['precipType', 'Type', 'summary', 'LCLid', 'stdorToU', 'Acorn'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Household id: 35\n",
      "Household id: 30\n",
      "Household id: 14\n",
      "Household id: 46\n",
      "Household id: 41\n",
      "Household id: 24\n",
      "Household id: 26\n",
      "Household id: 37\n",
      "Household id: 6\n",
      "Household id: 45\n",
      "Household id: 19\n",
      "Household id: 3\n",
      "Household id: 39\n",
      "Household id: 32\n",
      "Household id: 8\n",
      "Household id: 22\n",
      "Household id: 11\n",
      "Household id: 38\n",
      "Household id: 42\n",
      "Household id: 10\n",
      "Household id: 15\n",
      "Household id: 16\n",
      "Household id: 29\n",
      "Household id: 36\n",
      "Household id: 1\n",
      "Household id: 23\n",
      "Household id: 31\n",
      "Household id: 28\n",
      "Household id: 21\n",
      "Household id: 7\n",
      "Household id: 49\n",
      "Household id: 17\n",
      "Household id: 27\n",
      "Household id: 0\n",
      "Household id: 44\n",
      "Household id: 5\n",
      "Household id: 40\n",
      "Household id: 12\n",
      "Household id: 48\n",
      "Household id: 33\n",
      "Household id: 13\n",
      "Household id: 2\n",
      "Household id: 50\n",
      "Household id: 43\n",
      "Household id: 25\n",
      "Household id: 34\n",
      "Household id: 20\n",
      "Household id: 18\n",
      "Household id: 4\n",
      "Household id: 9\n",
      "Household id: 47\n"
     ]
    }
   ],
   "source": [
    "# process fourier features for each group and saved each group's deterministic process\n",
    "import math\n",
    "\n",
    "dps = {}\n",
    "\n",
    "all_household_ids = encoded_df['household_label'].unique()\n",
    "households_grp = encoded_df.groupby('household_label')\n",
    "training_df = []\n",
    "testing_df = []\n",
    "\n",
    "for household_id in all_household_ids:\n",
    "    # get the household from the entire df\n",
    "    print(\"Household id:\", household_id)\n",
    "    singlehousehold_df = households_grp.get_group(household_id).sort_values(by='tstp', ascending=True)\n",
    "\n",
    "    # split into train, test\n",
    "    cutoff_point = math.floor(singlehousehold_df.shape[0] * 0.9)\n",
    "    training_singlehousehold_df = singlehousehold_df.iloc[:cutoff_point].reset_index()\n",
    "    testing_singlehousehold_df = singlehousehold_df.iloc[cutoff_point:].reset_index()\n",
    "\n",
    "    # create fourier features\n",
    "    fourier_obj = create_fourier(training_singlehousehold_df.set_index('tstp').asfreq('h').index)\n",
    "    fourier_train_features = fourier_obj.in_sample().reset_index().drop(['tstp'], axis=1)\n",
    "    training_singlehousehold_df = pd.concat([training_singlehousehold_df, fourier_train_features], axis=1)\n",
    "    fourier_test_features = fourier_obj.out_of_sample(testing_singlehousehold_df.shape[0]).reset_index().drop(['index'], axis=1)\n",
    "    testing_singlehousehold_df = pd.concat([testing_singlehousehold_df.reset_index().drop(['index'], axis=1), fourier_test_features], axis=1)\n",
    "    \n",
    "    # save the dp object\n",
    "    dps[household_id] = fourier_obj\n",
    "\n",
    "    # append to the household_dfs list\n",
    "    training_df.append(training_singlehousehold_df)\n",
    "    testing_df.append(testing_singlehousehold_df)\n",
    "\n",
    "training_df = pd.concat(training_df, axis=0)\n",
    "testing_df = pd.concat(testing_df, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(686587, 1, 134)\n",
      "(76315, 1, 134)\n"
     ]
    }
   ],
   "source": [
    "# scale the values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# drop unnecessary columns\n",
    "training_df = training_df.drop(['index', 'tstp'], axis=1)\n",
    "testing_df = testing_df.drop(['level_0', 'tstp'], axis=1)\n",
    "\n",
    "# separate into features and target\n",
    "X_train = training_df.drop(['energy(kWh/hh)'], axis=1)\n",
    "X_test = testing_df.drop(['energy(kWh/hh)'], axis=1)\n",
    "y_train = training_df['energy(kWh/hh)']\n",
    "y_test = testing_df['energy(kWh/hh)']\n",
    "\n",
    "# store the household ids for future evaluation\n",
    "test_household_ids = X_test['household_label']\n",
    "train_household_ids = X_train['household_label']\n",
    "\n",
    "# Scale with MinMax Normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) # scale to 0 and 1\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# reshape for LSTM, CNN-LSTM models\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def adjusted_r2(y_pred, y_test):\n",
    "   p = X_train.shape[2]\n",
    "   r2 = r2_score(y_pred, y_test)\n",
    "   n = y_test.shape[0]\n",
    "   \n",
    "   adjusted_coefficient = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "   return adjusted_coefficient\n",
    "\n",
    "def evaluate_model(y_pred, y_test, deep_learning):\n",
    "  \"\"\"\n",
    "    Evaluate the model predictions with all the regression metrics\n",
    "  \"\"\"\n",
    "  if deep_learning:\n",
    "    prediction = y_pred.ravel()\n",
    "\n",
    "  else:\n",
    "    prediction = y_pred\n",
    "\n",
    "  print(\"RMSE:\", mean_squared_error(prediction, y_test, squared=False))\n",
    "  print(\"MSE:\", mean_squared_error(prediction, y_test, squared=True))\n",
    "  print(\"MAE:\", mean_absolute_error(prediction, y_test))\n",
    "  print(\"MAPE:\", mean_absolute_percentage_error(prediction, y_test))\n",
    "  print(\"R2 Score:\", r2_score(prediction, y_test))\n",
    "  print(\"Adjusted R2 Score:\", adjusted_r2(prediction, y_test))\n",
    "\n",
    "def plot_forecast(y_pred, y_test, number_of_slices=3, steps=168, skip=0):\n",
    "    \"\"\"\n",
    "      Plot the forecasted values against the truth values for LSTM and CNN-LSTM\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(number_of_slices, 1, sharey=True, figsize=(14, 10))\n",
    "    timesteps = np.arange(0, steps)\n",
    "    \n",
    "    for i in range(number_of_slices):\n",
    "        start_idx = 0 + (steps * i) + (skip)\n",
    "        end_idx = steps * (1 + i) + (skip)\n",
    "        sampled_test = y_test.iloc[start_idx:end_idx]\n",
    "        sampled_pred = y_pred.reshape(-1)[start_idx:end_idx]\n",
    "        mape_score = mean_absolute_percentage_error(sampled_test, sampled_pred)\n",
    "        \n",
    "        sns.lineplot(x=timesteps, y=y_test.iloc[start_idx:end_idx], label=\"truth-value\", marker='o', alpha=0.3, ax=axes[i])\n",
    "        sns.lineplot(x=timesteps, y=y_pred.reshape(-1)[start_idx:end_idx], label=\"pred-value\", marker='o', ax=axes[i])\n",
    "        axes[i].set_title(f'MAPE: {round(mape_score, 2)}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4087/4087 [==============================] - 36s 8ms/step - loss: 2.4158 - mae: 0.2067 - mse: 0.1395 - mape: 1375725.0000 - val_loss: 0.1523 - val_mae: 0.1827 - val_mse: 0.1256 - val_mape: 559695.2500\n",
      "Epoch 2/50\n",
      "4087/4087 [==============================] - 31s 7ms/step - loss: 0.0965 - mae: 0.1441 - mse: 0.0741 - mape: 785554.0625 - val_loss: 0.0598 - val_mae: 0.1053 - val_mse: 0.0310 - val_mape: 337159.8750\n",
      "Epoch 3/50\n",
      "4087/4087 [==============================] - 32s 8ms/step - loss: 0.0295 - mae: 0.0494 - mse: 0.0068 - mape: 516746.5312 - val_loss: 0.0214 - val_mae: 0.0383 - val_mse: 0.0043 - val_mape: 366523.4688\n",
      "Epoch 4/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0184 - mae: 0.0363 - mse: 0.0037 - mape: 421660.7500 - val_loss: 0.0162 - val_mae: 0.0277 - val_mse: 0.0038 - val_mape: 310152.8750\n",
      "Epoch 5/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0158 - mae: 0.0347 - mse: 0.0036 - mape: 390530.6250 - val_loss: 0.0186 - val_mae: 0.0319 - val_mse: 0.0038 - val_mape: 247317.9688\n",
      "Epoch 6/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0144 - mae: 0.0332 - mse: 0.0034 - mape: 374883.0938 - val_loss: 0.0135 - val_mae: 0.0178 - val_mse: 0.0037 - val_mape: 233303.3281\n",
      "Epoch 7/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0135 - mae: 0.0320 - mse: 0.0032 - mape: 360260.7500 - val_loss: 0.0134 - val_mae: 0.0201 - val_mse: 0.0037 - val_mape: 338609.4062\n",
      "Epoch 8/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0128 - mae: 0.0310 - mse: 0.0030 - mape: 339529.7188 - val_loss: 0.0120 - val_mae: 0.0176 - val_mse: 0.0030 - val_mape: 264225.1875\n",
      "Epoch 9/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0121 - mae: 0.0299 - mse: 0.0028 - mape: 324817.7188 - val_loss: 0.0120 - val_mae: 0.0185 - val_mse: 0.0034 - val_mape: 243604.8906\n",
      "Epoch 10/50\n",
      "4087/4087 [==============================] - 31s 7ms/step - loss: 0.0116 - mae: 0.0287 - mse: 0.0026 - mape: 308697.3125 - val_loss: 0.0172 - val_mae: 0.0612 - val_mse: 0.0069 - val_mape: 145256.1406\n",
      "Epoch 11/50\n",
      "4087/4087 [==============================] - 32s 8ms/step - loss: 0.0112 - mae: 0.0281 - mse: 0.0025 - mape: 297793.3125 - val_loss: 0.0105 - val_mae: 0.0166 - val_mse: 0.0022 - val_mape: 204733.3906\n",
      "Epoch 12/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0108 - mae: 0.0272 - mse: 0.0023 - mape: 285900.7812 - val_loss: 0.0109 - val_mae: 0.0204 - val_mse: 0.0028 - val_mape: 238638.5156\n",
      "Epoch 13/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0106 - mae: 0.0269 - mse: 0.0023 - mape: 287287.3438 - val_loss: 0.0102 - val_mae: 0.0278 - val_mse: 0.0026 - val_mape: 39967.6211\n",
      "Epoch 14/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0102 - mae: 0.0258 - mse: 0.0021 - mape: 271108.1250 - val_loss: 0.0124 - val_mae: 0.0273 - val_mse: 0.0026 - val_mape: 142850.7656\n",
      "Epoch 15/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0099 - mae: 0.0254 - mse: 0.0020 - mape: 277332.1875 - val_loss: 0.0093 - val_mae: 0.0193 - val_mse: 0.0019 - val_mape: 186609.7969\n",
      "Epoch 16/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0097 - mae: 0.0252 - mse: 0.0019 - mape: 262644.8750 - val_loss: 0.0119 - val_mae: 0.0318 - val_mse: 0.0028 - val_mape: 501505.0938\n",
      "Epoch 17/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0095 - mae: 0.0247 - mse: 0.0019 - mape: 265185.0000 - val_loss: 0.0125 - val_mae: 0.0412 - val_mse: 0.0035 - val_mape: 164415.3906\n",
      "Epoch 18/50\n",
      "4087/4087 [==============================] - 32s 8ms/step - loss: 0.0092 - mae: 0.0243 - mse: 0.0018 - mape: 254170.7344 - val_loss: 0.0087 - val_mae: 0.0173 - val_mse: 0.0013 - val_mape: 186725.1250\n",
      "Epoch 19/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0091 - mae: 0.0240 - mse: 0.0018 - mape: 246870.0312 - val_loss: 0.0086 - val_mae: 0.0214 - val_mse: 0.0017 - val_mape: 163356.5000\n",
      "Epoch 20/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0090 - mae: 0.0242 - mse: 0.0018 - mape: 257620.8281 - val_loss: 0.0079 - val_mae: 0.0126 - val_mse: 0.0012 - val_mape: 103373.7344\n",
      "Epoch 21/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0088 - mae: 0.0237 - mse: 0.0016 - mape: 251275.6562 - val_loss: 0.0093 - val_mae: 0.0266 - val_mse: 0.0018 - val_mape: 339121.0938\n",
      "Epoch 22/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0086 - mae: 0.0234 - mse: 0.0016 - mape: 246754.7500 - val_loss: 0.0076 - val_mae: 0.0123 - val_mse: 0.0010 - val_mape: 107328.5234\n",
      "Epoch 23/50\n",
      "4087/4087 [==============================] - 27s 7ms/step - loss: 0.0086 - mae: 0.0236 - mse: 0.0016 - mape: 250308.2812 - val_loss: 0.0079 - val_mae: 0.0213 - val_mse: 0.0011 - val_mape: 290121.8750\n",
      "Epoch 24/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0084 - mae: 0.0233 - mse: 0.0016 - mape: 246563.4688 - val_loss: 0.0109 - val_mae: 0.0516 - val_mse: 0.0036 - val_mape: 215020.5938\n",
      "Epoch 25/50\n",
      "4087/4087 [==============================] - 27s 7ms/step - loss: 0.0083 - mae: 0.0232 - mse: 0.0016 - mape: 256804.9688 - val_loss: 0.0073 - val_mae: 0.0173 - val_mse: 8.9057e-04 - val_mape: 160033.5625\n",
      "Epoch 26/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0082 - mae: 0.0231 - mse: 0.0015 - mape: 248449.3281 - val_loss: 0.0070 - val_mae: 0.0114 - val_mse: 6.1170e-04 - val_mape: 200649.5469\n",
      "Epoch 27/50\n",
      "4087/4087 [==============================] - 27s 7ms/step - loss: 0.0081 - mae: 0.0227 - mse: 0.0015 - mape: 243275.0469 - val_loss: 0.0073 - val_mae: 0.0166 - val_mse: 9.5337e-04 - val_mape: 69663.8672\n",
      "Epoch 28/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0080 - mae: 0.0227 - mse: 0.0015 - mape: 241907.5938 - val_loss: 0.0075 - val_mae: 0.0232 - val_mse: 0.0012 - val_mape: 267224.6562\n",
      "Epoch 29/50\n",
      "4087/4087 [==============================] - 27s 7ms/step - loss: 0.0079 - mae: 0.0226 - mse: 0.0015 - mape: 241941.1094 - val_loss: 0.0071 - val_mae: 0.0116 - val_mse: 9.8147e-04 - val_mape: 126414.1016\n",
      "Epoch 30/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0078 - mae: 0.0225 - mse: 0.0014 - mape: 248440.3281 - val_loss: 0.0066 - val_mae: 0.0111 - val_mse: 6.1552e-04 - val_mape: 153543.7812\n",
      "Epoch 31/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0078 - mae: 0.0226 - mse: 0.0015 - mape: 246054.1875 - val_loss: 0.0066 - val_mae: 0.0113 - val_mse: 4.9724e-04 - val_mape: 139373.4531\n",
      "Epoch 32/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0076 - mae: 0.0224 - mse: 0.0014 - mape: 243328.7188 - val_loss: 0.0068 - val_mae: 0.0206 - val_mse: 9.4032e-04 - val_mape: 123343.3125\n",
      "Epoch 33/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0077 - mae: 0.0224 - mse: 0.0014 - mape: 243569.4531 - val_loss: 0.0107 - val_mae: 0.0431 - val_mse: 0.0042 - val_mape: 76973.4766\n",
      "Epoch 34/50\n",
      "4087/4087 [==============================] - 27s 7ms/step - loss: 0.0076 - mae: 0.0224 - mse: 0.0014 - mape: 249454.7969 - val_loss: 0.0071 - val_mae: 0.0182 - val_mse: 0.0013 - val_mape: 114955.6484\n",
      "Epoch 35/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0076 - mae: 0.0227 - mse: 0.0015 - mape: 250187.2656 - val_loss: 0.0062 - val_mae: 0.0104 - val_mse: 3.1525e-04 - val_mape: 139100.1094\n",
      "Epoch 36/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0074 - mae: 0.0220 - mse: 0.0014 - mape: 240092.9688 - val_loss: 0.0066 - val_mae: 0.0162 - val_mse: 5.7959e-04 - val_mape: 138391.6875\n",
      "Epoch 37/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0074 - mae: 0.0219 - mse: 0.0013 - mape: 243037.9688 - val_loss: 0.0067 - val_mae: 0.0166 - val_mse: 6.8591e-04 - val_mape: 264095.7812\n",
      "Epoch 38/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0074 - mae: 0.0224 - mse: 0.0014 - mape: 252197.6250 - val_loss: 0.0069 - val_mae: 0.0187 - val_mse: 7.0099e-04 - val_mape: 282814.2812\n",
      "Epoch 39/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0073 - mae: 0.0220 - mse: 0.0013 - mape: 245909.0938 - val_loss: 0.0064 - val_mae: 0.0210 - val_mse: 7.6500e-04 - val_mape: 112579.4453\n",
      "Epoch 40/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0073 - mae: 0.0223 - mse: 0.0014 - mape: 246756.8281 - val_loss: 0.0062 - val_mae: 0.0142 - val_mse: 5.3317e-04 - val_mape: 153449.5312\n"
     ]
    }
   ],
   "source": [
    "# Train with the best hyperparameter set\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, LSTM,\n",
    "    TimeDistributed, Dropout, Input\n",
    ")\n",
    "\n",
    "# for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=5)\n",
    "\n",
    "# input \n",
    "input_layer = Input(shape=(1, X_train.shape[2]))\n",
    "\n",
    "# stacked lstm\n",
    "lstm1 = LSTM(200, return_sequences=True)(input_layer)\n",
    "lstm2 = LSTM(200, return_sequences=True)(lstm1)\n",
    "dropout1 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# full connected layer\n",
    "fc1 = TimeDistributed(Dense(168, activation='relu', kernel_regularizer='l1'))(dropout1)\n",
    "fc2 = TimeDistributed(Dense(64, activation='relu'))(fc1)\n",
    "\n",
    "# output\n",
    "output_layer = TimeDistributed(Dense(1))(fc2)  \n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.MSE,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=['mae', 'mse', 'mape']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=168,\n",
    "    callbacks=[earlystop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model\n",
    "\n",
    "model.save(\"models\\\\lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def pinball_loss(y, y_hat, alpha):\n",
    "  \"\"\"\n",
    "    Loss function for the deep learning models\n",
    "  \"\"\"\n",
    "\n",
    "  error = (y - y_hat)\n",
    "  loss = tf.keras.backend.mean(\n",
    "    tf.keras.backend.maximum(alpha * error, (alpha - 1) * error), \n",
    "    axis=-1\n",
    "  )\n",
    "\n",
    "  return loss\n",
    "\n",
    "def plot_training_metrics(history):\n",
    "  \"\"\"\n",
    "    Function to plot the training metrics of the deep learning models\n",
    "  \"\"\"\n",
    "  training_metrics = history.history\n",
    "  loss = training_metrics['loss']\n",
    "  val_loss = training_metrics['val_loss']\n",
    "  loss_20 = training_metrics['output_20_loss']\n",
    "  val_loss_20 = training_metrics['val_output_20_loss']\n",
    "  loss_50 = training_metrics['output_50_loss']\n",
    "  val_loss_50 = training_metrics['val_output_50_loss']\n",
    "  loss_80 = training_metrics['output_80_loss']\n",
    "  val_loss_80 = training_metrics['val_output_80_loss']\n",
    "\n",
    "\n",
    "  timesteps = np.arange(len(loss))\n",
    "  fig, axes = plt.subplots(2, 2, sharey=True, figsize=(14, 10))\n",
    "\n",
    "  sns.lineplot(x=timesteps, y=loss, label='loss', marker='o', ax=axes[0][0])\n",
    "  sns.lineplot(x=timesteps, y=val_loss, label='val_loss', marker='o', ax=axes[0][0])\n",
    "  axes[0][0].set_title(\"Loss vs Validation Loss\")\n",
    "  axes[0][0].set_xlabel(\"Epochs\")  \n",
    "  axes[0][0].set_ylabel(\"Overall Loss\")\n",
    "\n",
    "  sns.lineplot(x=timesteps, y=loss_20, label='loss_20', marker='o', ax=axes[0][1])\n",
    "  sns.lineplot(x=timesteps, y=val_loss_20, label='val_loss_20', marker='o', ax=axes[0][1])\n",
    "  axes[0][1].set_title(\"Loss vs Validation Loss; alpha=0.2\")\n",
    "  axes[0][1].set_xlabel(\"Epochs\")  \n",
    "  axes[0][1].set_ylabel(\"Pinball Loss\")\n",
    "\n",
    "  sns.lineplot(x=timesteps, y=loss_50, label='loss_50', marker='o', ax=axes[1][0])\n",
    "  sns.lineplot(x=timesteps, y=val_loss_50, label='val_loss_50', marker='o', ax=axes[1][0])\n",
    "  axes[1][0].set_title(\"Loss vs Validation Loss; alpha=0.5\")\n",
    "  axes[1][0].set_xlabel(\"Epochs\")  \n",
    "  axes[1][0].set_ylabel(\"Pinball Loss\")\n",
    "\n",
    "  sns.lineplot(x=timesteps, y=loss_80, label='loss_80', marker='o', ax=axes[1][1])\n",
    "  sns.lineplot(x=timesteps, y=val_loss_80, label='val_loss_80', marker='o', ax=axes[1][1])\n",
    "  axes[1][1].set_title(\"Loss vs Validation Loss; alpha=0.8\")\n",
    "  axes[1][1].set_xlabel(\"Epochs\")  \n",
    "  axes[1][1].set_ylabel(\"Pinball Loss\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4087/4087 [==============================] - 37s 9ms/step - loss: 2.9377 - output_20_loss: 0.0599 - output_50_loss: 0.1074 - output_80_loss: 0.1064 - val_loss: 0.2908 - val_output_20_loss: 0.0647 - val_output_50_loss: 0.1065 - val_output_80_loss: 0.0959\n",
      "Epoch 2/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.2436 - output_20_loss: 0.0534 - output_50_loss: 0.0882 - output_80_loss: 0.0801 - val_loss: 0.2561 - val_output_20_loss: 0.0599 - val_output_50_loss: 0.0940 - val_output_80_loss: 0.0825\n",
      "Epoch 3/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.2258 - output_20_loss: 0.0512 - output_50_loss: 0.0821 - output_80_loss: 0.0733 - val_loss: 0.2387 - val_output_20_loss: 0.0569 - val_output_50_loss: 0.0871 - val_output_80_loss: 0.0760\n",
      "Epoch 4/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.2131 - output_20_loss: 0.0493 - output_50_loss: 0.0771 - output_80_loss: 0.0678 - val_loss: 0.2236 - val_output_20_loss: 0.0541 - val_output_50_loss: 0.0808 - val_output_80_loss: 0.0695\n",
      "Epoch 5/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.1990 - output_20_loss: 0.0468 - output_50_loss: 0.0712 - output_80_loss: 0.0611 - val_loss: 0.2022 - val_output_20_loss: 0.0501 - val_output_50_loss: 0.0717 - val_output_80_loss: 0.0592\n",
      "Epoch 6/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.1698 - output_20_loss: 0.0400 - output_50_loss: 0.0575 - output_80_loss: 0.0459 - val_loss: 0.1310 - val_output_20_loss: 0.0323 - val_output_50_loss: 0.0387 - val_output_80_loss: 0.0254\n",
      "Epoch 7/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.1063 - output_20_loss: 0.0209 - output_50_loss: 0.0283 - output_80_loss: 0.0207 - val_loss: 0.0659 - val_output_20_loss: 0.0119 - val_output_50_loss: 0.0115 - val_output_80_loss: 0.0092\n",
      "Epoch 8/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0800 - output_20_loss: 0.0141 - output_50_loss: 0.0201 - output_80_loss: 0.0152 - val_loss: 0.0533 - val_output_20_loss: 0.0101 - val_output_50_loss: 0.0093 - val_output_80_loss: 0.0061\n",
      "Epoch 9/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0689 - output_20_loss: 0.0121 - output_50_loss: 0.0173 - output_80_loss: 0.0132 - val_loss: 0.0492 - val_output_20_loss: 0.0069 - val_output_50_loss: 0.0074 - val_output_80_loss: 0.0097\n",
      "Epoch 10/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0626 - output_20_loss: 0.0108 - output_50_loss: 0.0157 - output_80_loss: 0.0120 - val_loss: 0.0464 - val_output_20_loss: 0.0057 - val_output_50_loss: 0.0081 - val_output_80_loss: 0.0090\n",
      "Epoch 11/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0584 - output_20_loss: 0.0101 - output_50_loss: 0.0146 - output_80_loss: 0.0111 - val_loss: 0.0430 - val_output_20_loss: 0.0084 - val_output_50_loss: 0.0074 - val_output_80_loss: 0.0049\n",
      "Epoch 12/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0550 - output_20_loss: 0.0094 - output_50_loss: 0.0136 - output_80_loss: 0.0104 - val_loss: 0.0392 - val_output_20_loss: 0.0052 - val_output_50_loss: 0.0057 - val_output_80_loss: 0.0071\n",
      "Epoch 13/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0522 - output_20_loss: 0.0089 - output_50_loss: 0.0128 - output_80_loss: 0.0098 - val_loss: 0.0367 - val_output_20_loss: 0.0049 - val_output_50_loss: 0.0054 - val_output_80_loss: 0.0063\n",
      "Epoch 14/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0501 - output_20_loss: 0.0085 - output_50_loss: 0.0123 - output_80_loss: 0.0094 - val_loss: 0.0355 - val_output_20_loss: 0.0067 - val_output_50_loss: 0.0052 - val_output_80_loss: 0.0043\n",
      "Epoch 15/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0481 - output_20_loss: 0.0082 - output_50_loss: 0.0118 - output_80_loss: 0.0090 - val_loss: 0.0342 - val_output_20_loss: 0.0048 - val_output_50_loss: 0.0047 - val_output_80_loss: 0.0057\n",
      "Epoch 16/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0466 - output_20_loss: 0.0079 - output_50_loss: 0.0114 - output_80_loss: 0.0088 - val_loss: 0.0348 - val_output_20_loss: 0.0061 - val_output_50_loss: 0.0051 - val_output_80_loss: 0.0049\n",
      "Epoch 17/50\n",
      "4087/4087 [==============================] - 31s 7ms/step - loss: 0.0453 - output_20_loss: 0.0077 - output_50_loss: 0.0111 - output_80_loss: 0.0085 - val_loss: 0.0310 - val_output_20_loss: 0.0038 - val_output_50_loss: 0.0040 - val_output_80_loss: 0.0051\n",
      "Epoch 18/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0441 - output_20_loss: 0.0075 - output_50_loss: 0.0108 - output_80_loss: 0.0082 - val_loss: 0.0348 - val_output_20_loss: 0.0031 - val_output_50_loss: 0.0067 - val_output_80_loss: 0.0075\n",
      "Epoch 19/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0431 - output_20_loss: 0.0073 - output_50_loss: 0.0105 - output_80_loss: 0.0080 - val_loss: 0.0297 - val_output_20_loss: 0.0047 - val_output_50_loss: 0.0039 - val_output_80_loss: 0.0041\n",
      "Epoch 20/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0423 - output_20_loss: 0.0072 - output_50_loss: 0.0103 - output_80_loss: 0.0079 - val_loss: 0.0300 - val_output_20_loss: 0.0051 - val_output_50_loss: 0.0046 - val_output_80_loss: 0.0036\n",
      "Epoch 21/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0414 - output_20_loss: 0.0070 - output_50_loss: 0.0101 - output_80_loss: 0.0077 - val_loss: 0.0287 - val_output_20_loss: 0.0039 - val_output_50_loss: 0.0037 - val_output_80_loss: 0.0048\n",
      "Epoch 22/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0408 - output_20_loss: 0.0069 - output_50_loss: 0.0100 - output_80_loss: 0.0076 - val_loss: 0.0298 - val_output_20_loss: 0.0049 - val_output_50_loss: 0.0047 - val_output_80_loss: 0.0044\n",
      "Epoch 23/50\n",
      "4087/4087 [==============================] - 31s 8ms/step - loss: 0.0401 - output_20_loss: 0.0068 - output_50_loss: 0.0098 - output_80_loss: 0.0074 - val_loss: 0.0287 - val_output_20_loss: 0.0056 - val_output_50_loss: 0.0037 - val_output_80_loss: 0.0036\n",
      "Epoch 24/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0396 - output_20_loss: 0.0068 - output_50_loss: 0.0097 - output_80_loss: 0.0074 - val_loss: 0.0272 - val_output_20_loss: 0.0041 - val_output_50_loss: 0.0034 - val_output_80_loss: 0.0041\n",
      "Epoch 25/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0391 - output_20_loss: 0.0067 - output_50_loss: 0.0096 - output_80_loss: 0.0073 - val_loss: 0.0287 - val_output_20_loss: 0.0053 - val_output_50_loss: 0.0050 - val_output_80_loss: 0.0030\n",
      "Epoch 26/50\n",
      "4087/4087 [==============================] - 28s 7ms/step - loss: 0.0385 - output_20_loss: 0.0066 - output_50_loss: 0.0094 - output_80_loss: 0.0072 - val_loss: 0.0273 - val_output_20_loss: 0.0043 - val_output_50_loss: 0.0039 - val_output_80_loss: 0.0041\n",
      "Epoch 27/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0381 - output_20_loss: 0.0065 - output_50_loss: 0.0093 - output_80_loss: 0.0071 - val_loss: 0.0279 - val_output_20_loss: 0.0043 - val_output_50_loss: 0.0043 - val_output_80_loss: 0.0041\n",
      "Epoch 28/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0377 - output_20_loss: 0.0065 - output_50_loss: 0.0093 - output_80_loss: 0.0071 - val_loss: 0.0254 - val_output_20_loss: 0.0039 - val_output_50_loss: 0.0027 - val_output_80_loss: 0.0040\n",
      "Epoch 29/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0373 - output_20_loss: 0.0064 - output_50_loss: 0.0092 - output_80_loss: 0.0070 - val_loss: 0.0267 - val_output_20_loss: 0.0050 - val_output_50_loss: 0.0044 - val_output_80_loss: 0.0027\n",
      "Epoch 30/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0369 - output_20_loss: 0.0064 - output_50_loss: 0.0091 - output_80_loss: 0.0069 - val_loss: 0.0292 - val_output_20_loss: 0.0062 - val_output_50_loss: 0.0064 - val_output_80_loss: 0.0022\n",
      "Epoch 31/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0364 - output_20_loss: 0.0063 - output_50_loss: 0.0090 - output_80_loss: 0.0068 - val_loss: 0.0245 - val_output_20_loss: 0.0042 - val_output_50_loss: 0.0033 - val_output_80_loss: 0.0028\n",
      "Epoch 32/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0362 - output_20_loss: 0.0063 - output_50_loss: 0.0089 - output_80_loss: 0.0068 - val_loss: 0.0258 - val_output_20_loss: 0.0031 - val_output_50_loss: 0.0035 - val_output_80_loss: 0.0051\n",
      "Epoch 33/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0359 - output_20_loss: 0.0062 - output_50_loss: 0.0089 - output_80_loss: 0.0067 - val_loss: 0.0271 - val_output_20_loss: 0.0053 - val_output_50_loss: 0.0042 - val_output_80_loss: 0.0035\n",
      "Epoch 34/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0356 - output_20_loss: 0.0062 - output_50_loss: 0.0088 - output_80_loss: 0.0067 - val_loss: 0.0245 - val_output_20_loss: 0.0037 - val_output_50_loss: 0.0031 - val_output_80_loss: 0.0041\n",
      "Epoch 35/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0354 - output_20_loss: 0.0061 - output_50_loss: 0.0088 - output_80_loss: 0.0067 - val_loss: 0.0254 - val_output_20_loss: 0.0038 - val_output_50_loss: 0.0032 - val_output_80_loss: 0.0049\n",
      "Epoch 36/50\n",
      "4087/4087 [==============================] - 29s 7ms/step - loss: 0.0352 - output_20_loss: 0.0061 - output_50_loss: 0.0087 - output_80_loss: 0.0066 - val_loss: 0.0270 - val_output_20_loss: 0.0031 - val_output_50_loss: 0.0046 - val_output_80_loss: 0.0056\n",
      "Epoch 37/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0349 - output_20_loss: 0.0061 - output_50_loss: 0.0087 - output_80_loss: 0.0066 - val_loss: 0.0263 - val_output_20_loss: 0.0054 - val_output_50_loss: 0.0045 - val_output_80_loss: 0.0026\n",
      "Epoch 38/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0347 - output_20_loss: 0.0060 - output_50_loss: 0.0086 - output_80_loss: 0.0066 - val_loss: 0.0279 - val_output_20_loss: 0.0062 - val_output_50_loss: 0.0063 - val_output_80_loss: 0.0020\n",
      "Epoch 39/50\n",
      "4087/4087 [==============================] - 30s 7ms/step - loss: 0.0346 - output_20_loss: 0.0060 - output_50_loss: 0.0086 - output_80_loss: 0.0065 - val_loss: 0.0270 - val_output_20_loss: 0.0052 - val_output_50_loss: 0.0049 - val_output_80_loss: 0.0037\n"
     ]
    }
   ],
   "source": [
    "# input \n",
    "input_layer = Input(shape=(1, X_train.shape[2]))\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# stacked lstm\n",
    "layer = LSTM(300, return_sequences=True)(input_layer)\n",
    "layer = Dropout(0.2)(layer)\n",
    "\n",
    "# full connected layer\n",
    "layer = TimeDistributed(Dense(168, activation='relu', kernel_regularizer='l1'))(layer)\n",
    "layer = TimeDistributed(Dense(64, activation='relu'))(layer)\n",
    "\n",
    "# output\n",
    "output_layer_20 = TimeDistributed(Dense(1), name=\"output_20\")(layer)\n",
    "output_layer_50 = TimeDistributed(Dense(1), name=\"output_50\")(layer)\n",
    "output_layer_80 = TimeDistributed(Dense(1), name=\"output_80\")(layer)\n",
    "model = Model(inputs=[input_layer], outputs=[output_layer_20, output_layer_50, output_layer_80])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss={\n",
    "        \"output_20\": lambda y, y_hat: pinball_loss(y, y_hat, 0.2),\n",
    "        \"output_50\": lambda y, y_hat: pinball_loss(y, y_hat, 0.5),\n",
    "        \"output_80\": lambda y, y_hat: pinball_loss(y, y_hat, 0.8)\n",
    "    }\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=168,\n",
    "    callbacks=[earlystop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models\\\\quantile_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
